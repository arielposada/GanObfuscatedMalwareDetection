
from fastai.vision.all import *
from fastai.data.transforms import *
import torch
import torch.nn as nn

import torch
import torch.nn as nn
import torch.optim as optim


from fastai.vision.all import *
import torch
import torch.nn.functional as F

import torch
from torchvision import transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

from datetime import datetime

batch_size = 64
img_height = 224
img_width = 224

path = '/home/ariel.posada/AFGIE1/NonObfuscatedImg'

path_goodware = Path('/home/ariel.posada/AFGIE1/Goodware/')
path_malware = Path('/home/ariel.posada/AFGIE1/Malware/')

def get_dls(bs=batch_size,size=img_height,path=path):
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
      get_items=get_image_files,
      splitter=RandomSplitter(valid_pct=0.2, seed=42),
      get_y=parent_label,
                       item_tfms=Resize(size))
      #item_tfms=Resize(224))
    #dls = dblock.dataloaders(path, bs=64)
    dls = dblock.dataloaders(path, bs=bs)
    dls.c = 3
    return dls

dls = get_dls()

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.conv = nn.Sequential(
            # Primer bloque convolucional
            nn.Conv2d(1, 64, kernel_size=3, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Segundo bloque convolucional
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Tercer bloque convolucional
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Cuarto bloque convolucional
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )

        self.fc_common = nn.Sequential(
            nn.Linear(512 * 14 * 14, 1024),
            nn.ReLU(True),
            nn.Dropout(0.3)
        )

        # Capa final para la decisión real/falso
        self.fc_real_fake = nn.Sequential(
            nn.Linear(1024 + 2, 1),
            nn.Sigmoid()
        )

        # Capa final para la clasificación goodware/malware
        self.fc_class = nn.Sequential(
            nn.Linear(1024 + 2, 2),
            nn.Softmax(dim=1)
        )

    def forward(self, image, labels):
        x = self.conv(image)
        x = x.view(x.size(0), -1)
        x = self.fc_common(x)

        # Convertir TensorImage y TensorCategory a torch.Tensor estándar
        x = torch.tensor(x, dtype=torch.float32)
        labels = torch.tensor(labels, dtype=torch.float32)
        x_rf = torch.cat([x, labels], 1)
        x_class = torch.cat([x, labels], 1)

        real_fake_output = self.fc_real_fake(x_rf)
        class_output = self.fc_class(x_class)

        return real_fake_output, class_output

discriminator = Discriminator()


# Configurar el dispositivo (usar GPU si está disponible)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Cargar el modelo pre-entrenado
model_path = '/home/ariel.posada/data/discriminator_20231128_023848.pth'
discriminator.load_state_dict(torch.load(model_path))
discriminator.to(device)

def get_predictions(discriminator, dls, batch_size):
    discriminator.eval() 
    predictions = []
    labels = []
    with torch.no_grad():  
        for images, labels_batch in dls:
            if images.size(0) < batch_size:
                continue
            if images.shape[1] == 3:  
                images = images.mean(dim=1, keepdim=True)

            # Crear un tensor de ceros para las etiquetas
            labels_zero = torch.zeros(labels_batch.size(0), 2).float()
            _, preds = discriminator(images, labels_zero)
            preds = preds.squeeze()

            # Verificar la dimensión de las predicciones
            if preds.ndim == 1:
                preds = preds.unsqueeze(1)

            predictions.extend(preds.argmax(dim=1).cpu().numpy())
            labels.extend(labels_batch.cpu().numpy())
    return predictions, labels

train_predictions, train_labels = get_predictions(discriminator, dls.train, batch_size)

eval_predictions, eval_labels = get_predictions(discriminator, dls.valid, batch_size)
 
predictions = train_predictions + eval_predictions
true_labels = train_labels + eval_labels

cm = confusion_matrix(true_labels, predictions)

# Visualizar la matriz de confusión
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = range(len(['Goodware', 'Malware']))
plt.xticks(tick_marks, ['Goodware', 'Malware'], rotation=45)
plt.yticks(tick_marks, ['Goodware', 'Malware'])

# Etiquetar los ejes
plt.xlabel('Predicted Label')
plt.ylabel('True Label')

# Añadir anotaciones de texto en cada celda
thresh = cm.max() / 2.
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, format(cm[i, j], 'd'),
             horizontalalignment="center",
             color="white" if cm[i, j] > thresh else "black")

# Guardar la matriz de confusión como PNG
fecha_actual = datetime.now().strftime("%Y%m%d_%H%M%S")
nombre_archivo_mc = f"/home/ariel.posada/data/mc_{fecha_actual}.png"
plt.savefig(nombre_archivo_mc)

# Se está evaluando el modelo guardado

#nombre_archivo_modelo = f"/home/ariel.posada/data/discriminator_{fecha_actual}.pth"
#torch.save(discriminator.state_dict(), nombre_archivo_modelo)

# /home/ariel.posada/data/discriminator_20231128_023848.pth