from fastai.vision.all import *
from fastai.vision.gan import *
from fastai.metrics import accuracy, Precision, Recall, F1Score
import datetime, os, json
from torchvision.utils import save_image
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import numpy as np
import sys

# Establecer el límite para el número de líneas de traceback a None para mostrar todo el traceback
sys.tracebacklimit = None

# Verificar si CUDA está disponible y asignar el dispositivo correspondiente
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Función de activación LeakyReLU
def leaky_relu():
    return nn.LeakyReLU(0.2, inplace=True)

# Clase para definir el crítico personalizado de la GAN
class CustomCritic(nn.Module):
    # Constructor de la clase
    def __init__(self, in_size, n_channels, n_features=64, n_extra_layers=0):
        super().__init__()
        # Definición de las capas convolucionales y la capa final lineal
        self.conv_layers = nn.Sequential(
            # Primera capa convolucional sin normalización y con LeakyReLU
            ConvLayer(n_channels, n_features, 4, 2, 1, norm_type=None, bias=False, act_cls=leaky_relu),
            # Capas convolucionales adicionales con normalización y LeakyReLU
            self._conv(n_features, n_features*2, 4, 2, 1, n_extra_layers),
            self._conv(n_features*2, n_features*4, 4, 2, 1),
            self._conv(n_features*4, n_features*8, 4, 2, 1),
            # Capa convolucional final que produce una salida única sin activación
            ConvLayer(n_features*8, 1, 4, padding=0, norm_type=None, act_cls=None, bias=False)
        )
        self.flatten = nn.Flatten()
        self.fc = nn.Linear(10*10, 2)

    # Método forward para la propagación hacia adelante
    def forward(self, x):
        x = self.conv_layers(x)
        x = self.flatten(x)
        return self.fc(x)

    # Método para crear capas convolucionales
    def _conv(self, ni, nf, ks=3, stride=2, padding=1, n_extra_layers=0):
        layers = [ConvLayer(ni, nf, ks, stride=stride, padding=padding, bias=False, norm_type=NormType.Batch, act_cls=leaky_relu)]
        for _ in range(n_extra_layers):
            layers.append(ConvLayer(nf, nf, ks, stride=1, padding=padding, bias=False, norm_type=NormType.Batch, act_cls=leaky_relu))
        return nn.Sequential(*layers)


# Función para crear un aprendiz (learner) para el crítico con fines de clasificación
def create_critic_classifier_learner(dls, metrics):
    critic = CustomCritic(in_size=224, n_channels=3, n_features=64, n_extra_layers=1)
    # Modificar la última capa para la clasificación binaria
    critic.fc = nn.Linear(critic.fc.in_features, 2)  # Cambiar a 2 para salida binaria
    learn = Learner(dls, critic, metrics=metrics, loss_func=nn.CrossEntropyLoss())
    return learn

# Ruta al directorio de imágenes Shikata
path = "/home/ariel.posada/AFGIE1/ShikataImg"
sufijo = 'Shikata'

log_file_path = "/home/ariel.posada/data/out/log.txt"

# Configuración de DataBlock y DataLoaders
dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
                   get_items=get_image_files,
                   splitter=RandomSplitter(valid_pct=0.2, seed=42),
                   get_y=parent_label,
                   item_tfms=Resize(224))
dls = dblock.dataloaders(path, bs=64)
dls = dls.to(device)

# Cargar el modelo pre-entrenado
path_to_pretrained_model = f'/home/ariel.posada/data/out/gan_trained_{sufijo}_202311071003'
# Crear el generador y el crítico
generator = basic_generator(out_size=224, n_channels=3, n_extra_layers=1)
critic = create_critic_classifier_learner(dls, metrics=[accuracy, Precision, Recall, F1Score])

# Crear un módulo GAN que contenga tanto el generador como el crítico
gan_model = GANModule(generator, critic)

# Cargar el modelo pre-entrenado
path_to_pretrained_model = '/home/ariel.posada/data/out/gan_trained_Shikata_202311071003.pth'

# Cargar los pesos en el módulo GAN
# Suponiendo que gan_model es una instancia de GANModule con atributos generator y critic
state_dict = torch.load(path_to_pretrained_model, map_location=device)['model']

# Cargar el estado del generador
generator_state_dict = {k.replace('generator.', ''): v for k, v in state_dict.items() if k.startswith('generator')}
gan_model.generator.load_state_dict(generator_state_dict)

# Cargar el estado del crítico
critic_state_dict = {k.replace('critic.', ''): v for k, v in state_dict.items() if k.startswith('critic')}
gan_model.critic.load_state_dict(critic_state_dict)


# Asegurarse de que el generador no se actualice
for param in gan_model.generator.parameters():
    param.requires_grad = False

 # Crear un Learner para el crítico
critic_learner = Learner(dls, gan_model.critic, metrics=[accuracy, Precision, Recall, F1Score], loss_func=nn.CrossEntropyLoss()).to(device)


# Entrenar el crítico como un clasificador binario
critic_learner.fit_one_cycle(4, 2e-4)

# Guardar el modelo de clasificación
current_time = datetime.datetime.now().strftime("%Y%m%d%H%M")
critic_learner.save(f'/home/ariel.posada/data/out/critic_classifier_{sufijo}_{current_time}')

# Evaluación del modelo de clasificación con los archivos originales
with open(log_file_path, "a") as log_file:
    print(f"Evaluating {sufijo} Critic Classifier Model with original files:", file=log_file)
    original_dls = dls.test_dl(get_image_files(path), with_labels=True)
    critic_learner.dls = original_dls  # Asignar el DataLoader original al learner para la evaluación
    preds, targs = critic_learner.get_preds(dl=original_dls)

    # Calcular la matriz de confusión
    cm = confusion_matrix(targs.numpy(), preds.argmax(dim=1).numpy())

    # Crear la figura para la matriz de confusión
    fig, ax = plt.subplots(figsize=(6,6))
    ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.7)
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(x=j, y=i, s=cm[i, j], va='center', ha='center')

    # Establecer las etiquetas de los ejes con las categorías del vocabulario
    categories = dls.vocab
    ax.set_xticklabels([''] + categories)
    ax.set_yticklabels([''] + categories)

    # Etiquetas y título
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(f'Confusion Matrix {sufijo}')

    # Guardar la figura
    plt.savefig(f'/home/ariel.posada/data/out/cm_critic_classifier_{sufijo}_{current_time}.png')
    plt.close()
