from fastai.vision import *
from fastai.vision.all import *
from fastai.vision.gan import *
from fastai.metrics import accuracy, Precision, Recall, F1Score
import datetime
from torchvision.utils import save_image
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import numpy as np
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F

# Se usan los parámetros originales, 64, 224
bs, size = 64, 224
#bs,size=32, 128
# bs,size = 24,160
#bs,size = 8,256
arch = resnet34

path = "/home/ariel.posada/AFGIE1/NonObfuscatedImg"

def get_dls(bs,size):
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
      get_items=get_image_files,
      splitter=RandomSplitter(valid_pct=0.2, seed=42),
      get_y=parent_label,
                       item_tfms=Resize(size))
      #item_tfms=Resize(224))
    #dls = dblock.dataloaders(path, bs=64)
    dls = dblock.dataloaders(path, bs=bs)
    dls.c = 3
    return dls

dls_gen = get_dls(bs,size)

wd = 1e-3
#loss_gen = MSELossFlat()
loss_gen = AdaptiveLoss(nn.BCEWithLogitsLoss())
y_range = ('Goodware','Malware')


# Establecer el límite para el número de líneas de traceback a None para mostrar todo el traceback
sys.tracebacklimit = None

# Verificar si CUDA está disponible y asignar el dispositivo correspondiente
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Función de activación LeakyReLU
def leaky_relu():
    return nn.LeakyReLU(0.2, inplace=True)

# Clase para definir el crítico personalizado de la GAN
class CustomCritic(nn.Module):
    def __init__(self, in_size, n_channels, n_features=64, n_extra_layers=0):
        super().__init__()
        self.conv_layers = nn.Sequential(
            ConvLayer(n_channels, n_features, 4, 2, 1, norm_type=None, bias=False, act_cls=leaky_relu),
            self._conv(n_features, n_features*2, 4, 2, 1, n_extra_layers),
            self._conv(n_features*2, n_features*4, 4, 2, 1),
            self._conv(n_features*4, n_features*8, 4, 2, 1),
            ConvLayer(n_features*8, 1, 4, padding=0, norm_type=None, act_cls=None, bias=False)
        )
        self.flatten = nn.Flatten()
        self.fc = nn.Linear(10*10, 1)

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.flatten(x)
        return self.fc(x)

    def _conv(self, ni, nf, ks=3, stride=2, padding=1, n_extra_layers=0):
        layers = [ConvLayer(ni, nf, ks, stride=stride, padding=padding, bias=False, norm_type=NormType.Batch, act_cls=leaky_relu)]
        for _ in range(n_extra_layers):
            layers.append(ConvLayer(nf, nf, ks, stride=1, padding=padding, bias=False, norm_type=NormType.Batch, act_cls=leaky_relu))
        return nn.Sequential(*layers)

# Función para crear un aprendiz (learner) para el crítico con fines de clasificación
def create_critic_classifier_learner(dls, metrics):
    critic = CustomCritic(in_size=224, n_channels=3, n_features=64, n_extra_layers=1)
    critic.fc = nn.Linear(critic.fc.in_features, 2)
    learn = Learner(dls, critic, metrics=metrics, loss_func=nn.CrossEntropyLoss())
    return learn


class ConditionalGenerator(nn.Module):
    def __init__(self, z_dim, img_channels, features_g, num_classes):
        super(ConditionalGenerator, self).__init__()

        # Capa para incrustar la etiqueta de clase
        self.label_emb = nn.Embedding(num_classes, z_dim)

        # Definir las capas del generador
        self.gen = nn.Sequential(
            # Bloque de entrada: z_dim -> features_g * 16
            self._block(z_dim, features_g * 16, 4, 1, 0),
            # features_g * 16 -> features_g * 8
            self._block(features_g * 16, features_g * 8, 4, 2, 1),
            # features_g * 8 -> features_g * 4
            self._block(features_g * 8, features_g * 4, 4, 2, 1),
            # features_g * 4 -> features_g * 2
            self._block(features_g * 4, features_g * 2, 4, 2, 1),
            # Capa final: features_g * 2 -> img_channels
            nn.ConvTranspose2d(features_g * 2, img_channels, kernel_size=4, stride=2, padding=1),
            nn.Tanh() # Las imágenes generadas deben estar en el rango [-1, 1]
        )

    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
        return nn.Sequential(
            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU()
        )

    def forward(self, noise, labels):
        # Incrustar la etiqueta y combinarla con el ruido
        label_embedding = self.label_emb(labels)
        x = torch.mul(noise, label_embedding)
        return self.gen(x)

# Ejemplo de inicialización del generador condicional
z_dim = 20  # Dimensión del espacio latente
img_channels = 3  # Canales de la imagen (RGB)
features_g = 32  # Características en las capas del generador
num_classes = 2  # 'Goodware' y 'Malware'
dls = get_dls(bs=64, size=224)

# Función para generar ruido aleatorio
def get_noise(batch_size, z_dim):
    return torch.randn(batch_size, z_dim, 1, 1)

def generator_loss(fake_outputs, _=None):
    # Crea un tensor de objetivos que represente las imágenes reales (un tensor de unos)
    real_labels = torch.ones_like(fake_outputs, device=device)
    # Calcula la pérdida usando BCEWithLogitsLoss
    loss = F.binary_cross_entropy_with_logits(fake_outputs, real_labels)
    return loss

# Modificar el Learner para manejar el ruido y las etiquetas
class ConditionalGanLearner(Learner):
    def one_batch(self, i, b):
        self.iter = i
        self._split(b)
        self('before_batch')

        # Generate random noise
        batch_size = self.xb[0].shape[0]
        noise = get_noise(batch_size, z_dim).to(self.dls.device)

        # Get labels
        labels = self.yb[0].to(self.dls.device)

        # Pass noise and labels to the generator
        self.pred = self.model(noise, labels)
        self('after_pred')
        
        # Calculate the generator loss
        self.loss_grad = generator_loss(self.pred)
        self.loss = self.loss_grad.clone()

        self('after_loss')
        if not self.training or not len(self.yb): return
        self('before_backward')
        self.loss_grad.backward()
        self._with_events(self.opt.step, 'step', CancelStepException)
        self.opt.zero_grad()


generator = ConditionalGenerator(z_dim, img_channels, features_g, num_classes)

learn_gen = ConditionalGanLearner(dls, generator, loss_func=generator_loss)
print("##################### Entrenando el generador ################")
# Entrenar el generador
learn_gen.fit_one_cycle(6, 1e-3)


critic_learner = create_critic_classifier_learner(dls_gen, metrics=[accuracy])
print("##################### Entrenando el crítico ################")
critic_learner.fit(6, 1e-3)

gan = GANModule(learn_gen.model, critic_learner.model)
learn_gan = Learner(dls_gen, gan, loss_func=AdaptiveLoss(nn.BCEWithLogitsLoss()), opt_func=partial(Adam, mom=0.))


print("##################### Entrenando la GAN ################")
# https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb
learn_gan.fit(40, 1e-4)

current_time = datetime.datetime.now().strftime("%Y%m%d%H%M")
learn_gan.save(f'/home/ariel.posada/data/out/gan_trained_NonObfuscatedImg_{current_time}')
