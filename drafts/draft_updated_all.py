from fastai.vision.all import *
from fastai.vision.gan import *
import fastai.torch_core
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.checkpoint import checkpoint
import argparse
import os
import math
import torchvision.transforms as transforms
from torchvision.utils import save_image
from torch.utils.data import DataLoader
from torchvision import datasets
from torch.autograd import Variable
import torch.nn.functional as F
import random
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.utils as vutils
import numpy as np
from torch.cuda.amp import GradScaler, autocast
import datetime
import threading
import time
import timm

bs, size = 8, 224
path = "/home/ariel.posada/AFGIE1/NonObfuscatedImg"
z_dim = 100  
num_classes = 2  # 'Goodware' y 'Malware'

def get_dls(bs, size):
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
                       get_items=get_image_files,
                       splitter=RandomSplitter(valid_pct=0.2, seed=42),
                       get_y=parent_label,
                       item_tfms=Resize(size))
    dls = dblock.dataloaders(path, bs=bs)
    dls.c = 3
    return dls

class TimmDiscriminator(nn.Module):
    def __init__(self, num_classes=1, pretrained=True):
        super().__init__()
        # Load the resnet18 model
        self.model = timm.create_model('resnet18', pretrained=pretrained, num_classes=num_classes)

    def forward(self, x):
        if x.size(1) == 1:  # Check if the input is single-channel
            x = x.repeat(1, 3, 1, 1)  # Repeat the channel to make it 3-channel
        return self.model(x)

class TimmGenerator(nn.Module):
    def __init__(self, z_dim, img_channels, img_size=224):
        super().__init__()
        self.img_size = img_size
        # Initial layer
        self.initial_layer = nn.Sequential(
            nn.Linear(z_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 128 * (img_size // 16) * (img_size // 16)),
            nn.ReLU()
        )
        self.upsample_blocks = nn.Sequential(
            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),
            nn.Tanh()
        )

    def forward(self, z):
        out = self.initial_layer(z)
        out = out.view(out.size(0), 128, self.img_size // 16, self.img_size // 16)
        img = self.upsample_blocks(out)
        return img


# Initialize the generator and discriminator
generator = TimmGenerator(z_dim, 3)  # Assuming 3 channels for RGB images
discriminator = TimmDiscriminator()

# Loss function
adversarial_loss = nn.BCELoss()

# Optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# DataLoader
dataloader = get_dls(bs, size)

# Training Loop
epochs = 50  # You can adjust the number of epochs
for epoch in range(epochs):
    for i, (imgs, _) in enumerate(dataloader):

        # Adversarial ground truths
        valid = Variable(torch.FloatTensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)
        fake = Variable(torch.FloatTensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)

        # Configure input
        real_imgs = Variable(imgs.type(torch.FloatTensor))

        # -----------------
        #  Train Generator
        # -----------------
        optimizer_G.zero_grad()

        # Sample noise as generator input
        z = Variable(torch.FloatTensor(np.random.normal(0, 1, (imgs.shape[0], z_dim))))

        # Generate a batch of images
        gen_imgs = generator(z)

        # Loss measures generator's ability to fool the discriminator
        g_loss = adversarial_loss(discriminator(gen_imgs), valid)

        g_loss.backward()
        optimizer_G.step()

        # ---------------------
        #  Train Discriminator
        # ---------------------
        optimizer_D.zero_grad()

        # Measure discriminator's ability to classify real from generated samples
        real_loss = adversarial_loss(discriminator(real_imgs), valid)
        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)
        d_loss = (real_loss + fake_loss) / 2

        d_loss.backward()
        optimizer_D.step()

        print(f"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]")
