from fastai.vision.all import *
import torch
import torch.nn as nn
import torch.nn.functional as F

bs, size = 64, 224
path = "/home/ariel.posada/AFGIE1/NonObfuscatedImg"
z_dim = 100  
num_classes = 2  # 'Goodware' y 'Malware'

def get_dls(bs, size):
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
                       get_items=get_image_files,
                       splitter=RandomSplitter(valid_pct=0.2, seed=42),
                       get_y=parent_label,
                       item_tfms=Resize(size))
    dls = dblock.dataloaders(path, bs=bs)
    dls.c = 3
    return dls

def get_one_hot_labels(labels, num_classes):
    return F.one_hot(labels, num_classes).float()

class ConditionalGenerator(nn.Module):
    def __init__(self, z_dim, img_size, n_channels, num_classes, n_features=64):
        super().__init__()
        self.label_emb = nn.Embedding(num_classes, z_dim)
        self.z_dim = z_dim
        self.img_size = img_size
        self.num_classes = num_classes
        self.gen = nn.Sequential(
            # Inicia con un vector de tamaño z_dim
            nn.ConvTranspose2d(z_dim, n_features * 16, 4, 1, 0, bias=False),
            nn.BatchNorm2d(n_features * 16),
            nn.ReLU(True),

            # Tamaño: 1024 x 4 x 4
            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            # Tamaño: 512 x 8 x 8
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            # Tamaño: 256 x 16 x 16
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            # Tamaño: 128 x 32 x 32
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            # Tamaño: 64 x 64 x 64
            nn.ConvTranspose2d(64, n_channels, 4, 2, 1, bias=False),
            nn.Tanh()  # Tamaño final: n_channels x 128 x 128
        )

    def forward(self, noise, labels):
        # Incrustar las etiquetas y sumarlas al ruido
        label_embedding = self.label_emb(labels)
        x = torch.add(noise, label_embedding)

        # Asegurar que x tenga las dimensiones correctas
        desired_channels, desired_height, desired_width = 100, 4, 4  # Ajustar según las dimensiones esperadas
        current_size = x.size()

        # Verificar y ajustar las dimensiones
        if current_size[1] < desired_channels:
            # Agregar padding (cero) si hay menos canales de los necesarios
            padding = desired_channels - current_size[1]
            x = F.pad(x, (0, 0, 0, 0, 0, padding), "constant", 0)
        elif current_size[1] > desired_channels:
            # Recortar si hay más canales de los necesarios
            x = x[:, :desired_channels, :, :]

        # Redimensionar x para que coincida con la entrada esperada de la primera capa convolucional transpuesta
        x = x.view(x.size(0), desired_channels, desired_height, desired_width)

        return self.gen(x)

# Clase para el Discriminador
class ConditionalDiscriminator(nn.Module):
    def __init__(self, img_size, n_channels, num_classes):
        super().__init__()
        self.img_size = img_size
        self.num_classes = num_classes
        self.disc = nn.Sequential(
            # Tamaño de entrada: n_channels x 224 x 224
            nn.Conv2d(n_channels + 1, 64, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            # Tamaño: 64 x 112 x 112
            nn.Conv2d(64, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            # Tamaño: 128 x 56 x 56
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            # Tamaño: 256 x 28 x 28
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            # Tamaño: 512 x 14 x 14
            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()  # Tamaño final: 1 x 1 x 1
        )
        self.label_conditioning = nn.Embedding(num_classes, img_size * img_size)

    def forward(self, images, labels):
        label_conditioning = self.label_conditioning(labels).view(labels.size(0), 1, img_size, img_size)
        images = torch.cat([images, label_conditioning], 1)
        return self.disc(images)

# Función para entrenar el generador
def train_generator(dls, generator, discriminator, optimizer_g):
    generator.train()
    for real_images, labels in dls.train:
        batch_size = real_images.size(0)
        noise = torch.randn(batch_size, z_dim, 1, 1)
        fake_images = generator(noise, labels)
        disc_pred = discriminator(fake_images, labels)
        loss = nn.BCEWithLogitsLoss()(disc_pred, torch.ones_like(disc_pred))
        optimizer_g.zero_grad()
        loss.backward()
        optimizer_g.step()

# Función para entrenar el discriminador
def train_discriminator(dls, generator, discriminator, optimizer_d):
    discriminator.train()
    for real_images, labels in dls.train:
        batch_size = real_images.size(0)
        noise = torch.randn(batch_size, z_dim, 1, 1)
        fake_images = generator(noise, labels).detach()
        real_pred = discriminator(real_images, labels)
        fake_pred = discriminator(fake_images, labels)
        real_loss = nn.BCEWithLogitsLoss()(real_pred, torch.ones_like(real_pred))
        fake_loss = nn.BCEWithLogitsLoss()(fake_pred, torch.zeros_like(fake_pred))
        loss = (real_loss + fake_loss) / 2
        optimizer_d.zero_grad()
        loss.backward()
        optimizer_d.step()

# Inicialización
dls = get_dls(bs, size)
generator = ConditionalGenerator(z_dim, size, 3, num_classes)
discriminator = ConditionalDiscriminator(size, 3, num_classes)
optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

# Entrenamiento
for epoch in range(20):
    print(f"Epoch {epoch+1}/{20} generator.")
    train_generator(dls, generator, discriminator, optimizer_g)
    print(f"Epoch {epoch+1}/{20} discriminator.")
    train_discriminator(dls, generator, discriminator, optimizer_d)
    print(f"Epoch {epoch+1}/{20} completed.")
