from fastai.vision.all import *
from fastai.vision.gan import *
from fastai.metrics import accuracy, Precision, Recall, F1Score
import datetime, os


def leaky_relu():
    return nn.LeakyReLU(0.2, inplace=True)

def create_critic_learner(dls, metrics):
    critic = CustomCritic(in_size=224, n_channels=3, n_features=64, n_extra_layers=1)
    learn = Learner(dls, critic, metrics=metrics)
    return learn

class CustomCritic(nn.Module):
    def __init__(self, in_size, n_channels, n_features=64, n_extra_layers=0):
        super().__init__()
        
        # Función para LeakyReLU
        def leaky_relu():
            return nn.LeakyReLU(0.2, inplace=True)
        
        self.conv_layers = nn.Sequential(
            ConvLayer(n_channels, n_features, 4, 2, 1, norm_type=None, bias=False, act_cls=leaky_relu),
            self._conv(n_features, n_features*2, 4, 2, 1, n_extra_layers),
            self._conv(n_features*2, n_features*4, 4, 2, 1),
            self._conv(n_features*4, n_features*8, 4, 2, 1),
            ConvLayer(n_features*8, 1, 4, padding=0, norm_type=None, act_cls=None, bias=False)
        )
        self.flatten = nn.Flatten()
        self.fc = nn.Linear(10*10, 1)

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.flatten(x)
        return self.fc(x)

    def _conv(self, ni, nf, ks=3, stride=2, padding=1, n_extra_layers=0):
        # Función para LeakyReLU
        def leaky_relu():
            return nn.LeakyReLU(0.2, inplace=True)
        
        layers = [ConvLayer(ni, nf, ks, stride=stride, padding=padding, bias=False, norm_type=NormType.Batch, act_cls=leaky_relu)]
        for _ in range(n_extra_layers): layers.append(ConvLayer(nf, nf, ks, stride=1, padding=padding, bias=False, norm_type=NormType.Batch, act_cls=leaky_relu))
        return nn.Sequential(*layers)


class AdaptiveLoss(nn.Module):
    def __init__(self, crit):
        super().__init__()
        self.crit = crit

    def forward(self, output, target):
        target = target.float()  # Convertir las etiquetas a Float
        output = output.squeeze()  # Eliminar la dimensión adicional
        return self.crit(output, target)

paths = ["/home/ariel.posada/AFGIE1/ShikataImg", 
         "/home/ariel.posada/AFGIE1/NonObfuscatedImg", 
         "/home/ariel.posada/AFGIE1/XORImg"]

sufijos = ['Shikata', 'NonObfuscated', 'XOR']

for path, sufijo in zip(paths, sufijos):
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
                       get_items=get_image_files,
                       splitter=RandomSplitter(valid_pct=0.2),
                       get_y=parent_label,
                       item_tfms=Resize(224))

    dls = dblock.dataloaders(path, bs=64)
    dls = dls.cuda()  # Asegurarse de que los dataloaders estén en la GPU si está disponible

    model_path = f'/home/ariel.posada/data/out/resnet18_{sufijo}.pth'

    if not os.path.exists(model_path):
        metrics = [accuracy, Precision(), Recall(), F1Score()]
        learn_resnet = cnn_learner(dls, resnet18, metrics=metrics, pretrained=True)
        learn_resnet.fine_tune(4)
        learn_resnet.save(model_path)
    else:
        learn_resnet = cnn_learner(dls, resnet18)
        learn_resnet.load(model_path)

    # Continuar con GAN
    critic_learner = create_critic_learner(dls, metrics=[accuracy])

    generator = basic_generator(out_size=224, n_channels=3, n_extra_layers=1)
    gen_images_folder = Path(f"/home/ariel.posada/data/Gan{sufijo}Img")
    gen_images_folder.mkdir(parents=True, exist_ok=True)
    current_time = datetime.datetime.now().strftime("%Y%m%d%H%M")
    
    class SaveGeneratedImagesCallback(Callback):
        def after_epoch(self):
            # Asegurarse de que la entrada al generador sea de tipo float
            fake_images = self.learn.model.generator(torch.randn(64, 100).cuda().float())  # Asegurarse de que esté en la GPU y sea float
            for i, img in enumerate(fake_images):
                save_image(img, gen_images_folder/f"{current_time}_epoch_{self.epoch}_img_{i}.png")

    gan = GANModule(generator, critic_learner.model)
    learn_gan = Learner(dls, gan, loss_func=AdaptiveLoss(nn.BCEWithLogitsLoss()), opt_func=partial(Adam, mom=0.), cbs=[SaveGeneratedImagesCallback()])
    learn_gan.fit(4, 2e-4)
    learn_gan.save(f'/home/ariel.posada/data/out/gan_trained_{sufijo}_{current_time}')

    # Evaluar y guardar métricas
    print(f"Evaluating {sufijo} Model:")
    loss_resnet, acc_resnet, prec_resnet, recall_resnet, f1_resnet = learn_resnet.validate()
    print(f"Loss: {loss_resnet}, Accuracy: {acc_resnet}, Precision: {prec_resnet}, Recall: {recall_resnet}, F1: {f1_resnet}")

    print(f"Evaluating {sufijo} GAN Model:")
    learn_gan.dls = dls
    loss_gan, acc_gan = learn_gan.validate()
    print(f"Loss: {loss_gan}, Accuracy: {acc_gan}")
