{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import timm\n",
    "\n",
    "batch_size = 64\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "path = \"C:/Users/ariel/OneDrive/Documents/URosario/MalwareClassificatorProject/NonObfuscatedImg\"\n",
    "\n",
    "# path = \"/home/ariel.posada/AFGIE1/NonObfuscatedImg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dls(bs=batch_size,size=img_height,path=path):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "      get_items=get_image_files,\n",
    "      splitter=RandomSplitter(valid_pct=0.33,seed=42),\n",
    "      get_y=parent_label,\n",
    "      item_tfms=Resize(size))\n",
    "    \n",
    "    dls = dblock.dataloaders(path, bs=bs)\n",
    "    dls.c = 2\n",
    "    return dls\n",
    "\n",
    "dls = get_dls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 46.8M/46.8M [00:03<00:00, 15.2MB/s]\n",
      "c:\\Users\\ariel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ariel\\.cache\\huggingface\\hub\\models--timm--resnet18.a1_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CGenerator, self).__init__()\n",
    "        # Concatenar ruido y etiquetas\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(100 + 2, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 7 * 7 * 512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.conv_trans = nn.Sequential(\n",
    "            # Primer bloque de deconvolución: de 7x7 a 14x14\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Segundo bloque de deconvolución: de 14x14 a 28x28\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Tercer bloque de deconvolución: de 28x28 a 56x56\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Cuarto bloque de deconvolución: de 56x56 a 112x112\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            # Quinto bloque de deconvolución: de 112x112 a 224x224\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            # Sexto bloque de deconvolución: de 224x224 a 224x224\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], 1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 512, 7, 7)\n",
    "        x = self.conv_trans(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # Use timm to create a ResNet18 model, without the final classification layer\n",
    "        self.resnet18 = timm.create_model('resnet18', pretrained=True, num_classes=0)\n",
    "\n",
    "        # Fully connected layers as in your structure\n",
    "        self.fc_common = nn.Sequential(\n",
    "            nn.Linear(512, 1024),  # Adjust the input size to match ResNet18's output\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Capa final para la decisión real/falso\n",
    "        self.fc_real_fake = nn.Sequential(\n",
    "            nn.Linear(1024 + 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Capa final para la clasificación goodware/malware\n",
    "        self.fc_class = nn.Sequential(\n",
    "            nn.Linear(1024 + 2, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, labels):\n",
    "        # Adjust 1-channel images to 3-channel\n",
    "        if image.shape[1] == 1:\n",
    "            image = image.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Extract features using ResNet18\n",
    "        x = self.resnet18(image)\n",
    "        \n",
    "        # Process through the fully connected layers\n",
    "        x = self.fc_common(x)\n",
    "        \n",
    "        # Convertir TensorImage y TensorCategory a torch.Tensor estándar\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        x_rf = torch.cat([x, labels], 1)\n",
    "        x_class = torch.cat([x, labels], 1)\n",
    "\n",
    "        real_fake_output = self.fc_real_fake(x_rf)\n",
    "        class_output = self.fc_class(x_class)\n",
    "\n",
    "        return real_fake_output, class_output\n",
    "\n",
    "\n",
    "\n",
    "discriminator = Discriminator()\n",
    "generator = CGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (fc_common): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (fc_real_fake): Sequential(\n",
       "    (0): Linear(in_features=1026, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (fc_class): Sequential(\n",
       "    (0): Linear(in_features=1026, out_features=2, bias=True)\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Configurar el dispositivo (usar GPU si está disponible)\n",
    "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "generator.to(device)\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar los optimizadores\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(gen, disc, images, labels, gen_opt, disc_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "\n",
    "    # Generar ruido\n",
    "    noise = torch.randn(images.size(0), 100).to(images.device)\n",
    "\n",
    "    # Entrenar el generador\n",
    "    gen_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    generated_images = gen(noise, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images, labels_one_hot)\n",
    "    gen_loss = loss_func.gen_loss(fake_pred, fake_class_pred, labels)\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "\n",
    "    # Entrenar el discriminador\n",
    "    disc_opt.zero_grad()\n",
    "    real_pred, real_class_pred = disc(images, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images.detach(), labels_one_hot)\n",
    "    disc_loss = loss_func.disc_loss(real_pred, fake_pred, real_class_pred, labels)\n",
    "    disc_loss.backward()\n",
    "    disc_opt.step()\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def disc_loss(self, real_pred, fake_pred, real_class_pred, labels):\n",
    "        # Pérdida para la clasificación real vs. falsa\n",
    "        real_loss = self.bce_loss(real_pred, torch.ones_like(real_pred))\n",
    "        fake_loss = self.bce_loss(fake_pred, torch.zeros_like(fake_pred))\n",
    "        # Pérdida para la clasificación goodware vs. malware\n",
    "        class_loss = self.ce_loss(real_class_pred, labels)\n",
    "        # Combinar las pérdidas\n",
    "        return real_loss + fake_loss + class_loss\n",
    "\n",
    "    def gen_loss(self, fake_pred, fake_class_pred, labels):\n",
    "        # Pérdida para engañar al discriminador\n",
    "        gen_loss = self.bce_loss(fake_pred, torch.ones_like(fake_pred))\n",
    "        # Pérdida para la clasificación correcta de las imágenes generadas\n",
    "        class_loss = self.ce_loss(fake_class_pred, labels)\n",
    "        # Combinar las pérdidas\n",
    "        return gen_loss + class_loss\n",
    "\n",
    "# Inicializar la función de pérdida\n",
    "loss_func = GANLoss()\n",
    "\n",
    "\n",
    "# Pre-entrenamiento de los modelos\n",
    "# Inicio\n",
    "def gen_loss_func(fake_pred, fake_class_pred, labels):\n",
    "    bce_loss = nn.BCELoss() \n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    gen_loss = bce_loss(fake_pred, torch.ones_like(fake_pred)) + ce_loss(fake_class_pred, labels)\n",
    "    return gen_loss\n",
    "\n",
    "def disc_loss_func(real_pred, real_class_pred, labels):\n",
    "    bce_loss = nn.BCELoss()\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    real_loss = bce_loss(real_pred, torch.ones_like(real_pred))\n",
    "    disc_loss = real_loss + ce_loss(real_class_pred, labels)\n",
    "    return disc_loss\n",
    "\n",
    "def train_gen_step(gen, disc, images, labels, gen_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "    gen_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    noise = torch.randn(images.size(0), 100).to(images.device)\n",
    "    generated_images = gen(noise, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images, labels_one_hot)\n",
    "    gen_loss = loss_func(fake_pred, fake_class_pred, labels)\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "    return gen_loss\n",
    "\n",
    "def train_disc_step(disc, images, labels, disc_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "    disc_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    real_pred, real_class_pred = disc(images, labels_one_hot)\n",
    "    disc_loss = loss_func(real_pred, real_class_pred, labels)\n",
    "    disc_loss.backward()\n",
    "    disc_opt.step()\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions(discriminator, dls, batch_size):\n",
    "    discriminator.eval() \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():  \n",
    "        for images, labels_batch in dls:\n",
    "            if images.shape[1] == 3:  \n",
    "                images = images.mean(dim=1, keepdim=True)\n",
    "\n",
    "            # Crear un tensor de ceros para las etiquetas\n",
    "            labels_zero = torch.zeros(labels_batch.size(0), 2).float()\n",
    "            _, preds = discriminator(images, labels_zero)\n",
    "            preds = preds.squeeze()\n",
    "\n",
    "            # Verificar la dimensión de las predicciones\n",
    "            if preds.ndim == 1:\n",
    "                preds = preds.unsqueeze(1)\n",
    "\n",
    "            predictions.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            labels.extend(labels_batch.cpu().numpy())\n",
    "    return predictions, labels\n",
    "\n",
    "# Calculate Accuracy\n",
    "def calculate_accuracy(predictions, true_labels):\n",
    "    correct = sum(pred == true for pred, true in zip(predictions, true_labels))\n",
    "    return correct / len(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EPOCHS = 60 \n",
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Discriminator Resnet18 Train Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        disc_loss = train_disc_step(discriminator, images_batch, labels_batch, disc_optimizer, disc_loss_func)\n",
    "    predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    print(f\"Discriminator Accuracy on Valid Dataset after Epoch {epoch+1}: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "fecha_actual_pre_train = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "nombre_archivo_mc_pre_gan = f\"discriminator_pre_gan_{fecha_actual_pre_train}.pth\"\n",
    "torch.save(discriminator.state_dict(), f\"{nombre_archivo_mc_pre_gan}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Generator Train Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        gen_loss = train_gen_step(generator, discriminator, images_batch, labels_batch, gen_optimizer, gen_loss_func)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuración\n",
    "# EPOCHS = 80 \n",
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Final Train Resnet18 Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        if images_batch.size(0) < batch_size:\n",
    "            continue\n",
    "        \n",
    "        images_batch = images_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "\n",
    "        # Entrenar un paso\n",
    "        gen_loss, disc_loss = train_step(generator, discriminator, images_batch, labels_batch, gen_optimizer, disc_optimizer, loss_func)\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    print(f\"Discriminator Accuracy on Valid Dataset after Epoch {epoch+1}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = range(len(['Goodware', 'Malware']))\n",
    "plt.xticks(tick_marks, ['Goodware', 'Malware'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Goodware', 'Malware'])\n",
    "\n",
    "# Etiquetar los ejes\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Añadir anotaciones de texto en cada celda\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "# Guardar la matriz de confusión como PNG\n",
    "fecha_actual = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "nombre_archivo_mc = f\"discriminator_Resnet18_mc_{fecha_actual}.png\"\n",
    "plt.savefig(nombre_archivo_mc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nombre_archivo_modelo = f\"discriminator_Resnet18_{fecha_actual}.pth\"\n",
    "torch.save(discriminator.state_dict(), nombre_archivo_modelo)\n",
    "\n",
    "nombre_archivo_modelo = f\"generator_Resnet18_{fecha_actual}.pth\"\n",
    "torch.save(generator.state_dict(), nombre_archivo_modelo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# /home/ariel.posada/data/discriminator_20231128_023848.pth\n",
    "\n",
    "# Reset the Discriminator\n",
    "discriminator.load_state_dict(torch.load(nombre_archivo_mc_pre_gan))\n",
    "\n",
    "# Train it again with normal training\n",
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Discriminator Resnet18 Train Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        disc_loss = train_disc_step(discriminator, images_batch, labels_batch, disc_optimizer, disc_loss_func)\n",
    "    predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    print(f\"Discriminator Accuracy on Valid Dataset after Epoch {epoch+1}: {accuracy:.4f}\")\n",
    "    print(f\"Real Epoch: {epoch+1 + 10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = range(len(['Goodware', 'Malware']))\n",
    "plt.xticks(tick_marks, ['Goodware', 'Malware'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Goodware', 'Malware'])\n",
    "\n",
    "# Etiquetar los ejes\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Añadir anotaciones de texto en cada celda\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "# Guardar la matriz de confusión como PNG\n",
    "fecha_actual = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "nombre_archivo_mc = f\"discriminator_Resnet18_nogan_{fecha_actual}.png\"\n",
    "plt.savefig(nombre_archivo_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nombre_archivo_modelo = f\"discriminator_Resnet18_nogan_{fecha_actual}.pth\"\n",
    "torch.save(discriminator.state_dict(), nombre_archivo_modelo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tensor_to_image(tensor, file_path=None):\n",
    "    tensor = tensor.detach().cpu()\n",
    "    img = transforms.ToPILImage()(tensor)\n",
    "\n",
    "    if file_path is not None:\n",
    "        img.save(file_path)\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generating malware images...\")\n",
    "\n",
    "# Generate 20 images of Malware\n",
    "for i in range(20):\n",
    "    noise = torch.randn(1, 100).to(device)\n",
    "    # Goodware = 0, Malware = 1\n",
    "    labels_one_hot = torch.tensor([[0, 1]]).float().to(device)\n",
    "\n",
    "    # Generate an image\n",
    "    img_tensor = generator(noise, labels_one_hot)\n",
    "    img = tensor_to_image(img_tensor[0])\n",
    "    # Display the image\n",
    "    tensor_to_image(img_tensor[0], f'img_Malware_{i+1}.png')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "print(f\"Generating goodware images...\")\n",
    "# Generate 20 images of Goodware\n",
    "for i in range(20):\n",
    "    noise = torch.randn(1, 100).to(device)\n",
    "    # Goodware = 1, Malware = 0\n",
    "    labels_one_hot = torch.tensor([[1, 0]]).float().to(device)\n",
    "\n",
    "    # Generate an image\n",
    "    img_tensor = generator(noise, labels_one_hot)\n",
    "    img = tensor_to_image(img_tensor[0])\n",
    "    # Display the image\n",
    "    tensor_to_image(img_tensor[0], f'img_Goodware_{i+1}.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
