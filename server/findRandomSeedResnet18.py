
from fastai.vision.all import *
from fastai.data.transforms import *
import torch
import torch.nn as nn

import torch
import torch.nn as nn
import torch.optim as optim


from fastai.vision.all import *
import torch
import torch.nn.functional as F

import torch
from torchvision import transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

from datetime import datetime

import timm

batch_size = 64
img_height = 224
img_width = 224

#path = "C:/Users/ariel/OneDrive/Documents/URosario/MalwareClassificatorProject/NonObfuscatedImg"
path = "/home/ariel.posada/AFGIE1/NonObfuscatedImg"


def get_dls(bs=batch_size,size=img_height,path=path,random_seed=123):
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
      get_items=get_image_files,
      splitter=RandomSplitter(valid_pct=0.5,seed=random_seed),
      get_y=parent_label,
      item_tfms=Resize(size))
    
    dls = dblock.dataloaders(path, bs=bs)
    dls.c = 2
    return dls

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        # Use timm to create a ResNet18 model, without the final classification layer
        self.resnet18 = timm.create_model('resnet18', pretrained=True, num_classes=0)

        # Fully connected layers as in your structure
        self.fc_common = nn.Sequential(
            nn.Linear(512, 1024),  # Adjust the input size to match ResNet18's output
            nn.ReLU(True),
            nn.Dropout(0.3)
        )

        # Capa final para la decisión real/falso
        self.fc_real_fake = nn.Sequential(
            nn.Linear(1024 + 2, 1),
            nn.Sigmoid()
        )

        # Capa final para la clasificación goodware/malware
        self.fc_class = nn.Sequential(
            nn.Linear(1024 + 2, 2),
            nn.Softmax(dim=1)
        )

    def forward(self, image, labels):
        # Adjust 1-channel images to 3-channel
        if image.shape[1] == 1:
            image = image.repeat(1, 3, 1, 1)

        # Extract features using ResNet18
        x = self.resnet18(image)
        
        # Process through the fully connected layers
        x = self.fc_common(x)
        
        # Convertir TensorImage y TensorCategory a torch.Tensor estándar
        x = torch.tensor(x, dtype=torch.float32)
        labels = torch.tensor(labels, dtype=torch.float32)
        x_rf = torch.cat([x, labels], 1)
        x_class = torch.cat([x, labels], 1)

        real_fake_output = self.fc_real_fake(x_rf)
        class_output = self.fc_class(x_class)

        return real_fake_output, class_output

 
def disc_loss_func(real_pred, real_class_pred, labels):
    bce_loss = nn.BCELoss()
    ce_loss = nn.CrossEntropyLoss()
    real_loss = bce_loss(real_pred, torch.ones_like(real_pred))
    disc_loss = real_loss + ce_loss(real_class_pred, labels)
    return disc_loss
 

def train_disc_step(disc, images, labels, disc_opt, loss_func):
    if images.shape[1] == 3:
        images = images.mean(dim=1, keepdim=True)
    disc_opt.zero_grad()
    labels_one_hot = F.one_hot(labels, num_classes=2).float()
    real_pred, real_class_pred = disc(images, labels_one_hot)
    disc_loss = loss_func(real_pred, real_class_pred, labels)
    disc_loss.backward()
    disc_opt.step()
    return disc_loss


def get_predictions(discriminator, dls, batch_size):
    discriminator.eval() 
    predictions = []
    labels = []
    with torch.no_grad():  
        for images, labels_batch in dls:
            if images.shape[1] == 3:  
                images = images.mean(dim=1, keepdim=True)

            # Crear un tensor de ceros para las etiquetas
            labels_zero = torch.zeros(labels_batch.size(0), 2).float()
            _, preds = discriminator(images, labels_zero)
            preds = preds.squeeze()

            # Verificar la dimensión de las predicciones
            if preds.ndim == 1:
                preds = preds.unsqueeze(1)

            predictions.extend(preds.argmax(dim=1).cpu().numpy())
            labels.extend(labels_batch.cpu().numpy())
    return predictions, labels

# Calculate Accuracy
def calculate_accuracy(predictions, true_labels):
    correct = sum(pred == true for pred, true in zip(predictions, true_labels))
    return correct / len(predictions)


for i_random_seed in range(200):
    dls = get_dls(random_seed=i_random_seed)

    discriminator = Discriminator() 

    # Configurar el dispositivo (usar GPU si está disponible)
    device = "cpu" # torch.device("cuda:0" if torch.cuda.is_available() else "cpu") 
    discriminator.to(device)

    # Inicializar los optimizadores 
    disc_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))
    EPOCHS = 3

    for epoch in range(EPOCHS):
        print(f"Discriminator Resnet18 Train Epoch {epoch+1}/{EPOCHS} with random seed {i_random_seed}")
        for images_batch, labels_batch in dls.train:
            disc_loss = train_disc_step(discriminator, images_batch, labels_batch, disc_optimizer, disc_loss_func)
        predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)
        accuracy = calculate_accuracy(predictions, true_labels)
        print(f"Discriminator Accuracy on Valid Dataset 50/50 after Epoch {epoch+1}: {accuracy:.4f}")

