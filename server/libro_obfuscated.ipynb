{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import timm\n",
    "\n",
    "batch_size = 64\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "\n",
    "path_xor = 'D:/Datasets/XORImg'\n",
    "path_shikata = 'D:/Datasets/ShikataImg'\n",
    "\n",
    "\n",
    "def get_combined_image_files(paths):\n",
    "    all_files = []\n",
    "    for path in paths:\n",
    "        all_files += get_image_files(path)\n",
    "    return all_files\n",
    "\n",
    "def get_dls(bs=batch_size,size=img_height,paths=[path_xor, path_shikata]):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "      get_items=lambda x: get_combined_image_files(paths),\n",
    "      splitter=RandomSplitter(valid_pct=0.2,seed=42),\n",
    "      get_y=parent_label,\n",
    "      item_tfms=Resize(size))\n",
    "\n",
    "    dls = dblock.dataloaders(paths, bs=bs)\n",
    "    dls.c = 2\n",
    "    return dls\n",
    "\n",
    "dls = get_dls()\n",
    "\n",
    "class CGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CGenerator, self).__init__()\n",
    "        # Concatenar ruido y etiquetas\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(100 + 2, 7 * 7 * 512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.conv_trans = nn.Sequential(\n",
    "            # Primer bloque de deconvolución: de 7x7 a 14x14\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Segundo bloque de deconvolución: de 14x14 a 28x28\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Tercer bloque de deconvolución: de 28x28 a 56x56\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Cuarto bloque de deconvolución: de 56x56 a 112x112\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            # Quinto bloque de deconvolución: de 112x112 a 224x224\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], 1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 512, 7, 7)\n",
    "        x = self.conv_trans(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # Use timm to create a ResNet18 model, without the final classification layer\n",
    "        self.resnet18 = timm.create_model('resnet18', pretrained=True, num_classes=0)\n",
    "\n",
    "        # Fully connected layers as in your structure\n",
    "        self.fc_common = nn.Sequential(\n",
    "            nn.Linear(512, 1024),  # Adjust the input size to match ResNet18's output\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Capa final para la decisión real/falso\n",
    "        self.fc_real_fake = nn.Sequential(\n",
    "            nn.Linear(1024 + 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Capa final para la clasificación goodware/malware\n",
    "        self.fc_class = nn.Sequential(\n",
    "            nn.Linear(1024 + 2, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, labels):\n",
    "        # Adjust 1-channel images to 3-channel\n",
    "        if image.shape[1] == 1:\n",
    "            image = image.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Extract features using ResNet18\n",
    "        x = self.resnet18(image)\n",
    "        \n",
    "        # Process through the fully connected layers\n",
    "        x = self.fc_common(x)\n",
    "        \n",
    "        # Convertir TensorImage y TensorCategory a torch.Tensor estándar\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        x_rf = torch.cat([x, labels], 1)\n",
    "        x_class = torch.cat([x, labels], 1)\n",
    "\n",
    "        real_fake_output = self.fc_real_fake(x_rf)\n",
    "        class_output = self.fc_class(x_class)\n",
    "\n",
    "        return real_fake_output, class_output\n",
    "\n",
    "\n",
    "\n",
    "discriminator = Discriminator()\n",
    "generator = CGenerator()\n",
    "\n",
    "# Configurar el dispositivo (usar GPU si está disponible)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# Inicializar los optimizadores\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "def train_step(gen, disc, images, labels, gen_opt, disc_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "\n",
    "    # Generar ruido\n",
    "    noise = torch.randn(images.size(0), 100).to(images.device)\n",
    "\n",
    "    # Entrenar el generador\n",
    "    gen_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    generated_images = gen(noise, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images, labels_one_hot)\n",
    "    gen_loss = loss_func.gen_loss(fake_pred, fake_class_pred, labels)\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "\n",
    "    # Entrenar el discriminador\n",
    "    disc_opt.zero_grad()\n",
    "    real_pred, real_class_pred = disc(images, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images.detach(), labels_one_hot)\n",
    "    disc_loss = loss_func.disc_loss(real_pred, fake_pred, real_class_pred, labels)\n",
    "    disc_loss.backward()\n",
    "    disc_opt.step()\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def disc_loss(self, real_pred, fake_pred, real_class_pred, labels):\n",
    "        # Pérdida para la clasificación real vs. falsa\n",
    "        real_loss = self.bce_loss(real_pred, torch.ones_like(real_pred))\n",
    "        fake_loss = self.bce_loss(fake_pred, torch.zeros_like(fake_pred))\n",
    "        # Pérdida para la clasificación goodware vs. malware\n",
    "        class_loss = self.ce_loss(real_class_pred, labels)\n",
    "        # Combinar las pérdidas\n",
    "        return real_loss + fake_loss + class_loss\n",
    "\n",
    "    def gen_loss(self, fake_pred, fake_class_pred, labels):\n",
    "        # Pérdida para engañar al discriminador\n",
    "        gen_loss = self.bce_loss(fake_pred, torch.ones_like(fake_pred))\n",
    "        # Pérdida para la clasificación correcta de las imágenes generadas\n",
    "        class_loss = self.ce_loss(fake_class_pred, labels)\n",
    "        # Combinar las pérdidas\n",
    "        return gen_loss + class_loss\n",
    "\n",
    "# Inicializar la función de pérdida\n",
    "loss_func = GANLoss()\n",
    "\n",
    "\n",
    "# Pre-entrenamiento de los modelos\n",
    "# Inicio\n",
    "def gen_loss_func(fake_pred, fake_class_pred, labels):\n",
    "    bce_loss = nn.BCELoss() \n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    gen_loss = bce_loss(fake_pred, torch.ones_like(fake_pred)) + ce_loss(fake_class_pred, labels)\n",
    "    return gen_loss\n",
    "\n",
    "def disc_loss_func(real_pred, real_class_pred, labels):\n",
    "    bce_loss = nn.BCELoss()\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    real_loss = bce_loss(real_pred, torch.ones_like(real_pred))\n",
    "    disc_loss = real_loss + ce_loss(real_class_pred, labels)\n",
    "    return disc_loss\n",
    "\n",
    "def train_gen_step(gen, disc, images, labels, gen_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "    gen_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    noise = torch.randn(images.size(0), 100).to(images.device)\n",
    "    generated_images = gen(noise, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images, labels_one_hot)\n",
    "    gen_loss = loss_func(fake_pred, fake_class_pred, labels)\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "    return gen_loss\n",
    "\n",
    "def train_disc_step(disc, images, labels, disc_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "    disc_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    real_pred, real_class_pred = disc(images, labels_one_hot)\n",
    "    disc_loss = loss_func(real_pred, real_class_pred, labels)\n",
    "    disc_loss.backward()\n",
    "    disc_opt.step()\n",
    "    return disc_loss\n",
    "\n",
    "\n",
    "def get_predictions(discriminator, dls, batch_size):\n",
    "    discriminator.eval() \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():  \n",
    "        for images, labels_batch in dls:\n",
    "            if images.shape[1] == 3:  \n",
    "                images = images.mean(dim=1, keepdim=True)\n",
    "\n",
    "            # Crear un tensor de ceros para las etiquetas\n",
    "            labels_zero = torch.zeros(labels_batch.size(0), 2).float()\n",
    "            _, preds = discriminator(images, labels_zero)\n",
    "            preds = preds.squeeze()\n",
    "\n",
    "            # Verificar la dimensión de las predicciones\n",
    "            if preds.ndim == 1:\n",
    "                preds = preds.unsqueeze(1)\n",
    "\n",
    "            predictions.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            labels.extend(labels_batch.cpu().numpy())\n",
    "    return predictions, labels\n",
    "\n",
    "# Calculate Accuracy\n",
    "def calculate_accuracy(predictions, true_labels):\n",
    "    correct = sum(pred == true for pred, true in zip(predictions, true_labels))\n",
    "    return correct / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Resnet18 obfuscated Train Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PlayerOne\\AppData\\Local\\Temp\\ipykernel_7240\\236617487.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float32)\n",
      "C:\\Users\\PlayerOne\\AppData\\Local\\Temp\\ipykernel_7240\\236617487.py:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32)\n",
      "c:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3176: DecompressionBombWarning: Image size (120716288 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3176: DecompressionBombWarning: Image size (114083840 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3176: DecompressionBombWarning: Image size (163307520 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3176: DecompressionBombWarning: Image size (168382464 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3176: DecompressionBombWarning: Image size (139471872 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Accuracy on Valid Dataset after Epoch 1: 0.9377\n",
      "Discriminator Resnet18 obfuscated Train Epoch 2/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 2: 0.9453\n",
      "Discriminator Resnet18 obfuscated Train Epoch 3/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 3: 0.9480\n",
      "Discriminator Resnet18 obfuscated Train Epoch 4/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 4: 0.9517\n",
      "Discriminator Resnet18 obfuscated Train Epoch 5/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 5: 0.9547\n",
      "Discriminator Resnet18 obfuscated Train Epoch 6/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 6: 0.9566\n",
      "Discriminator Resnet18 obfuscated Train Epoch 7/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 7: 0.9575\n",
      "Discriminator Resnet18 obfuscated Train Epoch 8/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 8: 0.9581\n",
      "Discriminator Resnet18 obfuscated Train Epoch 9/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 9: 0.9587\n",
      "Discriminator Resnet18 obfuscated Train Epoch 10/10\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 10: 0.9594\n",
      "Generator Train obfuscated Epoch 1/10\n",
      "Generator Train obfuscated Epoch 2/10\n",
      "Generator Train obfuscated Epoch 3/10\n",
      "Generator Train obfuscated Epoch 4/10\n",
      "Generator Train obfuscated Epoch 5/10\n",
      "Generator Train obfuscated Epoch 6/10\n",
      "Generator Train obfuscated Epoch 7/10\n",
      "Generator Train obfuscated Epoch 8/10\n",
      "Generator Train obfuscated Epoch 9/10\n",
      "Generator Train obfuscated Epoch 10/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# EPOCHS = 60 \n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Discriminator Resnet18 obfuscated Train Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        disc_loss = train_disc_step(discriminator, images_batch, labels_batch, disc_optimizer, disc_loss_func)\n",
    "    predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    print(f\"Discriminator Accuracy on Valid Dataset after Epoch {epoch+1}: {accuracy:.4f}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Generator Train obfuscated Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        gen_loss = train_gen_step(generator, discriminator, images_batch, labels_batch, gen_optimizer, gen_loss_func)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Resnet18 obfuscated Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PlayerOne\\AppData\\Local\\Temp\\ipykernel_7240\\236617487.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float32)\n",
      "C:\\Users\\PlayerOne\\AppData\\Local\\Temp\\ipykernel_7240\\236617487.py:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinal Train Resnet18 obfuscated Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m images_batch, labels_batch \u001b[39min\u001b[39;00m dls\u001b[39m.\u001b[39mtrain:\n\u001b[0;32m      7\u001b[0m         \u001b[39mif\u001b[39;00m images_batch\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m<\u001b[39m batch_size:\n\u001b[0;32m      8\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\load.py:127\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbefore_iter()\n\u001b[0;32m    126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__idxs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_idxs() \u001b[39m# called in context of main process (not workers/subprocesses)\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m _loaders[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfake_l\u001b[39m.\u001b[39mnum_workers\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m](\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfake_l):\n\u001b[0;32m    128\u001b[0m     \u001b[39m# pin_memory causes tuples to be converted to lists, so convert them back to tuples\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpin_memory \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(b) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m: b \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(b)\n\u001b[0;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: b \u001b[39m=\u001b[39m to_device(b, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:41\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_iter)\n\u001b[0;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\load.py:138\u001b[0m, in \u001b[0;36mDataLoader.create_batches\u001b[1;34m(self, samps)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mit \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m    137\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m o:o \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_item, samps))\n\u001b[1;32m--> 138\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_batch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunkify(res))\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\basics.py:230\u001b[0m, in \u001b[0;36mchunked\u001b[1;34m(it, chunk_sz, drop_last, n_chunks)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(it, Iterator): it \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(it)\n\u001b[0;32m    229\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mislice(it, chunk_sz))\n\u001b[0;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mand\u001b[39;00m (\u001b[39mlen\u001b[39m(res)\u001b[39m==\u001b[39mchunk_sz \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m drop_last): \u001b[39myield\u001b[39;00m res\n\u001b[0;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(res)\u001b[39m<\u001b[39mchunk_sz: \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\load.py:153\u001b[0m, in \u001b[0;36mDataLoader.do_item\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_item\u001b[39m(\u001b[39mself\u001b[39m, s):\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_item(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_item(s))\n\u001b[0;32m    154\u001b[0m     \u001b[39mexcept\u001b[39;00m SkipItemException: \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\load.py:160\u001b[0m, in \u001b[0;36mDataLoader.create_item\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_item\u001b[39m(\u001b[39mself\u001b[39m, s):\n\u001b[1;32m--> 160\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindexed: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[s \u001b[39mor\u001b[39;49;00m \u001b[39m0\u001b[39;49m]\n\u001b[0;32m    161\u001b[0m     \u001b[39melif\u001b[39;00m s \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mit)\n\u001b[0;32m    162\u001b[0m     \u001b[39melse\u001b[39;00m: \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index an iterable dataset numerically - must use `None`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\core.py:458\u001b[0m, in \u001b[0;36mDatasets.__getitem__\u001b[1;34m(self, it)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, it):\n\u001b[1;32m--> 458\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([tl[it] \u001b[39mfor\u001b[39;49;00m tl \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtls])\n\u001b[0;32m    459\u001b[0m     \u001b[39mreturn\u001b[39;00m res \u001b[39mif\u001b[39;00m is_indexer(it) \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mres))\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\core.py:458\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, it):\n\u001b[1;32m--> 458\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([tl[it] \u001b[39mfor\u001b[39;00m tl \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls])\n\u001b[0;32m    459\u001b[0m     \u001b[39mreturn\u001b[39;00m res \u001b[39mif\u001b[39;00m is_indexer(it) \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mres))\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\core.py:417\u001b[0m, in \u001b[0;36mTfmdLists.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    415\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(idx)\n\u001b[0;32m    416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_item \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m--> 417\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_after_item(res) \u001b[39mif\u001b[39;00m is_indexer(idx) \u001b[39melse\u001b[39;00m res\u001b[39m.\u001b[39mmap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_item)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\data\\core.py:377\u001b[0m, in \u001b[0;36mTfmdLists._after_item\u001b[1;34m(self, o)\u001b[0m\n\u001b[1;32m--> 377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_after_item\u001b[39m(\u001b[39mself\u001b[39m, o): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtfms(o)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\transform.py:208\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, o)\u001b[0m\n\u001b[1;32m--> 208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, o): \u001b[39mreturn\u001b[39;00m compose_tfms(o, tfms\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs, split_idx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit_idx)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\transform.py:158\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[1;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m tfms:\n\u001b[0;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_enc: f \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mdecode\n\u001b[1;32m--> 158\u001b[0m     x \u001b[39m=\u001b[39m f(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    159\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\transform.py:81\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m---> 81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m'\u001b[39;49m\u001b[39mencodes\u001b[39;49m\u001b[39m'\u001b[39;49m, x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\transform.py:91\u001b[0m, in \u001b[0;36mTransform._call\u001b[1;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, fn, x, split_idx\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m split_idx\u001b[39m!=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_idx \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_idx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m---> 91\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, fn), x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\transform.py:97\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[1;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m     96\u001b[0m     ret \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreturns(x) \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(f,\u001b[39m'\u001b[39m\u001b[39mreturns\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mreturn\u001b[39;00m retain_type(f(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), x, ret)\n\u001b[0;32m     98\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(f, x_, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m x_ \u001b[39min\u001b[39;00m x)\n\u001b[0;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastcore\\dispatch.py:120\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minst \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: f \u001b[39m=\u001b[39m MethodType(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minst)\n\u001b[0;32m    119\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mowner \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: f \u001b[39m=\u001b[39m MethodType(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mowner)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\vision\\core.py:125\u001b[0m, in \u001b[0;36mPILBase.create\u001b[1;34m(cls, fn, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fn,\u001b[39mbytes\u001b[39m): fn \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(fn)\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fn,Image\u001b[39m.\u001b[39mImage): \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(fn)\n\u001b[1;32m--> 125\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(load_image(fn, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmerge(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_open_args, kwargs)))\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\vision\\core.py:98\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(fn, mode)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image\u001b[39m(fn, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOpen and load a `PIL.Image` and convert to `mode`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 98\u001b[0m     im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(fn)\n\u001b[0;32m     99\u001b[0m     im\u001b[39m.\u001b[39mload()\n\u001b[0;32m    100\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39m_new(im\u001b[39m.\u001b[39mim)\n",
      "File \u001b[1;32mc:\\Users\\PlayerOne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3236\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3233\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3235\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3236\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3237\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3239\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuración\n",
    "EPOCHS = 80 \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Final Train Resnet18 obfuscated Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        if images_batch.size(0) < batch_size:\n",
    "            continue\n",
    "        \n",
    "        images_batch = images_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "\n",
    "        # Entrenar un paso\n",
    "        gen_loss, disc_loss = train_step(generator, discriminator, images_batch, labels_batch, gen_optimizer, disc_optimizer, loss_func)\n",
    "\n",
    "    # Calculate Accuracy\n",
    "\n",
    "    predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    print(f\"Discriminator Accuracy on Valid Dataset after Epoch {epoch+1}: {accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = range(len(['Goodware', 'Malware']))\n",
    "plt.xticks(tick_marks, ['Goodware', 'Malware'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Goodware', 'Malware'])\n",
    "\n",
    "# Etiquetar los ejes\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Añadir anotaciones de texto en cada celda\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "# Guardar la matriz de confusión como PNG\n",
    "fecha_actual = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "nombre_archivo_mc = f\"discriminator_Resnet18_obfuscated_mc_{fecha_actual}.png\"\n",
    "plt.savefig(nombre_archivo_mc)\n",
    "\n",
    "nombre_archivo_modelo = f\"discriminator_Resnet18_obfuscated_{fecha_actual}.pth\"\n",
    "torch.save(discriminator.state_dict(), nombre_archivo_modelo)\n",
    "\n",
    "\n",
    "nombre_archivo_modelo = f\"generator_Resnet18_obfuscated_{fecha_actual}.pth\"\n",
    "torch.save(generator.state_dict(), nombre_archivo_modelo)\n",
    "\n",
    "# /home/ariel.posada/data/discriminator_20231128_023848.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
