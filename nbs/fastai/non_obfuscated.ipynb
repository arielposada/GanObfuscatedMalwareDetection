{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import timm\n",
    "\n",
    "# 7 due to size of dataset\n",
    "batch_size = 7 #64\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "path = \"C:\\\\Github\\\\GanObfuscatedMalwareDetection\\\\test\" # Set Path to Dataset \n",
    "\n",
    "def get_dls(bs=batch_size,size=img_height,path=path):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "      get_items=get_image_files,\n",
    "      # 10% due to size of dataset\n",
    "      splitter=RandomSplitter(valid_pct=0.2,seed=42),\n",
    "      get_y=parent_label,\n",
    "      item_tfms=Resize(size))\n",
    "    \n",
    "    dls = dblock.dataloaders(path, bs=bs)\n",
    "    dls.c = 2\n",
    "    return dls\n",
    "\n",
    "dls = get_dls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suprimir todos los warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CGenerator, self).__init__()\n",
    "        # Concatenar ruido y etiquetas\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(100 + 2, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 7 * 7 * 512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.conv_trans = nn.Sequential(\n",
    "            # Primer bloque de deconvolución: de 7x7 a 14x14\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Segundo bloque de deconvolución: de 14x14 a 28x28\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Tercer bloque de deconvolución: de 28x28 a 56x56\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Cuarto bloque de deconvolución: de 56x56 a 112x112\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            # Quinto bloque de deconvolución: de 112x112 a 224x224\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            # Sexto bloque de deconvolución: de 224x224 a 224x224\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], 1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 512, 7, 7)\n",
    "        x = self.conv_trans(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # Use timm to create a ResNet18 model, without the final classification layer\n",
    "        # Revisar si no está pre-entrenado como pasa\n",
    "        # pretrained=False\n",
    "        self.resnet18 = timm.create_model('resnet18', pretrained=False, num_classes=0)\n",
    "\n",
    "        # Fully connected layers as in your structure\n",
    "        self.fc_common = nn.Sequential(\n",
    "            nn.Linear(512, 1024),  # Adjust the input size to match ResNet18's output\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Capa final para la decisión real/falso\n",
    "        self.fc_real_fake = nn.Sequential(\n",
    "            nn.Linear(1024 + 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Capa final para la clasificación goodware/malware\n",
    "        self.fc_class = nn.Sequential(\n",
    "            nn.Linear(1024 + 2, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, labels):\n",
    "        # Adjust 1-channel images to 3-channel\n",
    "        if image.shape[1] == 1:\n",
    "            image = image.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Extract features using ResNet18\n",
    "        x = self.resnet18(image)\n",
    "        \n",
    "        # Process through the fully connected layers\n",
    "        x = self.fc_common(x)\n",
    "        \n",
    "        # Convertir TensorImage y TensorCategory a torch.Tensor estándar\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        x_rf = torch.cat([x, labels], 1)\n",
    "        x_class = torch.cat([x, labels], 1)\n",
    "\n",
    "        real_fake_output = self.fc_real_fake(x_rf)\n",
    "        class_output = self.fc_class(x_class)\n",
    "\n",
    "        return real_fake_output, class_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "discriminator = Discriminator()\n",
    "generator = CGenerator()\n",
    "\n",
    "# Configurar el dispositivo (usar GPU si está disponible)\n",
    "device = \"cpu\" # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# Inicializar los optimizadores\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(gen, disc, images, labels, gen_opt, disc_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "\n",
    "    # Generar ruido\n",
    "    noise = torch.randn(images.size(0), 100).to(images.device)\n",
    "\n",
    "    # Entrenar el generador\n",
    "    gen_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    generated_images = gen(noise, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images, labels_one_hot)\n",
    "    gen_loss = loss_func.gen_loss(fake_pred, fake_class_pred, labels)\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "\n",
    "    # Entrenar el discriminador\n",
    "    disc_opt.zero_grad()\n",
    "    real_pred, real_class_pred = disc(images, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images.detach(), labels_one_hot)\n",
    "    disc_loss = loss_func.disc_loss(real_pred, fake_pred, real_class_pred, labels)\n",
    "    disc_loss.backward()\n",
    "    disc_opt.step()\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def disc_loss(self, real_pred, fake_pred, real_class_pred, labels):\n",
    "        # Pérdida para la clasificación real vs. falsa\n",
    "        real_loss = self.bce_loss(real_pred, torch.ones_like(real_pred))\n",
    "        fake_loss = self.bce_loss(fake_pred, torch.zeros_like(fake_pred))\n",
    "        # Pérdida para la clasificación goodware vs. malware\n",
    "        class_loss = self.ce_loss(real_class_pred, labels)\n",
    "        # Combinar las pérdidas\n",
    "        return real_loss + fake_loss + class_loss\n",
    "\n",
    "    def gen_loss(self, fake_pred, fake_class_pred, labels):\n",
    "        # Pérdida para engañar al discriminador\n",
    "        gen_loss = self.bce_loss(fake_pred, torch.ones_like(fake_pred))\n",
    "        # Pérdida para la clasificación correcta de las imágenes generadas\n",
    "        class_loss = self.ce_loss(fake_class_pred, labels)\n",
    "        # Combinar las pérdidas\n",
    "        return gen_loss + class_loss\n",
    "\n",
    "# Inicializar la función de pérdida\n",
    "loss_func = GANLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pre-entrenamiento de los modelos\n",
    "# Inicio\n",
    "def gen_loss_func(fake_pred, fake_class_pred, labels):\n",
    "    bce_loss = nn.BCELoss() \n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    gen_loss = bce_loss(fake_pred, torch.ones_like(fake_pred)) + ce_loss(fake_class_pred, labels)\n",
    "    return gen_loss\n",
    "\n",
    "def disc_loss_func(real_pred, real_class_pred, labels):\n",
    "    bce_loss = nn.BCELoss()\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    real_loss = bce_loss(real_pred, torch.ones_like(real_pred))\n",
    "    disc_loss = real_loss + ce_loss(real_class_pred, labels)\n",
    "    return disc_loss\n",
    "\n",
    "def train_gen_step(gen, disc, images, labels, gen_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "    gen_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    noise = torch.randn(images.size(0), 100).to(images.device)\n",
    "    generated_images = gen(noise, labels_one_hot)\n",
    "    fake_pred, fake_class_pred = disc(generated_images, labels_one_hot)\n",
    "    gen_loss = loss_func(fake_pred, fake_class_pred, labels)\n",
    "    gen_loss.backward()\n",
    "    gen_opt.step()\n",
    "    return gen_loss\n",
    "\n",
    "def train_disc_step(disc, images, labels, disc_opt, loss_func):\n",
    "    if images.shape[1] == 3:\n",
    "        images = images.mean(dim=1, keepdim=True)\n",
    "    disc_opt.zero_grad()\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "    real_pred, real_class_pred = disc(images, labels_one_hot)\n",
    "    disc_loss = loss_func(real_pred, real_class_pred, labels)\n",
    "    disc_loss.backward()\n",
    "    disc_opt.step()\n",
    "    return disc_loss\n",
    "\n",
    "\n",
    "def get_predictions(discriminator, dls, batch_size):\n",
    "    discriminator.eval() \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():  \n",
    "        for images, labels_batch in dls:\n",
    "            if images.shape[1] == 3:  \n",
    "                images = images.mean(dim=1, keepdim=True)\n",
    "\n",
    "            # Crear un tensor de ceros para las etiquetas\n",
    "            labels_zero = torch.zeros(labels_batch.size(0), 2).float()\n",
    "            _, preds = discriminator(images, labels_zero)\n",
    "            preds = preds.squeeze()\n",
    "\n",
    "            # Verificar la dimensión de las predicciones\n",
    "            if preds.ndim == 1:\n",
    "                preds = preds.unsqueeze(1)\n",
    "\n",
    "            predictions.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            labels.extend(labels_batch.cpu().numpy())\n",
    "    return predictions, labels\n",
    "\n",
    "# Calculate Accuracy\n",
    "def calculate_accuracy(predictions, true_labels):\n",
    "    correct = sum(pred == true for pred, true in zip(predictions, true_labels))\n",
    "    return correct / len(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Resnet18 Train Epoch 1/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 1: 0.4643\n",
      "Discriminator Resnet18 Train Epoch 2/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 2: 0.4643\n",
      "Discriminator Resnet18 Train Epoch 3/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 3: 0.8571\n",
      "Discriminator Resnet18 Train Epoch 4/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 4: 0.8929\n",
      "Discriminator Resnet18 Train Epoch 5/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 5: 0.6071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# EPOCHS = 5 \n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Discriminator Resnet18 Train Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        disc_loss = train_disc_step(discriminator, images_batch, labels_batch, disc_optimizer, disc_loss_func)\n",
    "    predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    print(f\"Discriminator Accuracy on Valid Dataset after Epoch {epoch+1}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Save the discriminator\n",
    "    \n",
    "fecha_actual_pre_train = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "nombre_archivo_mc_pre_gan = f\"output/discriminator_pre_gan_{fecha_actual_pre_train}.pth\"\n",
    "torch.save(discriminator.state_dict(), f\"{nombre_archivo_mc_pre_gan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator Train Epoch 1/5\n",
      "generator Train Epoch 2/5\n",
      "generator Train Epoch 3/5\n",
      "generator Train Epoch 4/5\n",
      "generator Train Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"generator Train Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        gen_loss = train_gen_step(generator, discriminator, images_batch, labels_batch, gen_optimizer, gen_loss_func)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Resnet18 Epoch 1/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 1: 0.7500\n",
      "Final Train Resnet18 Epoch 2/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 2: 0.6429\n",
      "Final Train Resnet18 Epoch 3/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 3: 0.6786\n",
      "Final Train Resnet18 Epoch 4/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 4: 0.7500\n",
      "Final Train Resnet18 Epoch 5/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 5: 0.6786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuración\n",
    "# EPOCHS = 80 \n",
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Final Train Resnet18 Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        if images_batch.size(0) < batch_size:\n",
    "            continue\n",
    "        \n",
    "        images_batch = images_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "\n",
    "        # Entrenar un paso\n",
    "        gen_loss, disc_loss = train_step(generator, discriminator, images_batch, labels_batch, gen_optimizer, disc_optimizer, loss_func)\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    print(f\"Discriminator Accuracy on Valid Dataset after Epoch {epoch+1}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fecha_actual = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "nombre_archivo_modelo = f\"output/discriminator_Resnet18_{fecha_actual}.pth\"\n",
    "torch.save(discriminator.state_dict(), nombre_archivo_modelo)\n",
    "\n",
    "nombre_archivo_modelo = f\"output/generator_Resnet18_{fecha_actual}.pth\"\n",
    "torch.save(generator.state_dict(), nombre_archivo_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Resnet18 Train Epoch 1/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 1: 0.6429\n",
      "Real Epoch: 11\n",
      "Discriminator Resnet18 Train Epoch 2/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 2: 0.7143\n",
      "Real Epoch: 12\n",
      "Discriminator Resnet18 Train Epoch 3/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 3: 0.7857\n",
      "Real Epoch: 13\n",
      "Discriminator Resnet18 Train Epoch 4/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 4: 0.7500\n",
      "Real Epoch: 14\n",
      "Discriminator Resnet18 Train Epoch 5/5\n",
      "Discriminator Accuracy on Valid Dataset after Epoch 5: 0.7500\n",
      "Real Epoch: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Reset the Discriminator\n",
    "discriminator.load_state_dict(torch.load(nombre_archivo_mc_pre_gan))\n",
    "\n",
    "# Train it again with normal training\n",
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Discriminator Resnet18 Train Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images_batch, labels_batch in dls.train:\n",
    "        disc_loss = train_disc_step(discriminator, images_batch, labels_batch, disc_optimizer, disc_loss_func)\n",
    "    predictions, true_labels = get_predictions(discriminator, dls.valid, batch_size)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    print(f\"Discriminator Accuracy on Valid Dataset after Epoch {epoch+1}: {accuracy:.4f}\")\n",
    "    print(f\"Real Epoch: {epoch+1 + 10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fecha_actual = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "nombre_archivo_modelo = f\"output/discriminator_Resnet18_nogan_{fecha_actual}.pth\"\n",
    "torch.save(discriminator.state_dict(), nombre_archivo_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating malware images...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tensor_to_image(tensor, file_path=None):\n",
    "    tensor = tensor.detach().cpu()\n",
    "    img = transforms.ToPILImage()(tensor)\n",
    "\n",
    "    if file_path is not None:\n",
    "        img.save(file_path)\n",
    "    \n",
    "    return img\n",
    "\n",
    "print(f\"Generating malware images...\")\n",
    "\n",
    "# Generate 20 images of Malware\n",
    "for i in range(20):\n",
    "    noise = torch.randn(1, 100).to(device)\n",
    "    # Goodware = 0, Malware = 1\n",
    "    labels_one_hot = torch.tensor([[0, 1]]).float().to(device)\n",
    "\n",
    "    # Generate an image\n",
    "    img_tensor = generator(noise, labels_one_hot)\n",
    "    img = tensor_to_image(img_tensor[0])\n",
    "    # Display the image\n",
    "    tensor_to_image(img_tensor[0], f'output/img_Malware_{i+1}.png')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating goodware images...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Generating goodware images...\")\n",
    "# Generate 20 images of Goodware\n",
    "for i in range(20):\n",
    "    noise = torch.randn(1, 100).to(device)\n",
    "    # Goodware = 1, Malware = 0\n",
    "    labels_one_hot = torch.tensor([[1, 0]]).float().to(device)\n",
    "\n",
    "    # Generate an image\n",
    "    img_tensor = generator(noise, labels_one_hot)\n",
    "    img = tensor_to_image(img_tensor[0])\n",
    "    # Display the image\n",
    "    tensor_to_image(img_tensor[0], f'output/img_Goodware_{i+1}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
